{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import io, os\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ! pip install librosa\n",
    "# ! pip install soundfile\n",
    "# ! pip install pyspark --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## librosa\n",
    "[librosa](https://librosa.github.io/librosa/index.html) is a Python package for music and audio processing by [Brian McFee](https://bmcfee.github.io/). A large portion was ported from [Dan Ellis's Matlab audio processing examples](http://www.ee.columbia.edu/~dpwe/resources/matlab/).\n",
    "\n",
    "If you receive an error with librosa.load, you may need to [install ffmpeg](https://librosa.github.io/librosa/install.html#ffmpeg)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IPython.display.Audio\n",
    "[IPython.display.Audio](https://ipython.org/ipython-doc/stable/api/generated/IPython.display.html#IPython.display.Audio) lets you play audio directly in an IPython notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apache Spark\n",
    "[Spark](https://spark.apache.org/docs/latest/) is used to do the parallel pre-processing of the audio data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!ls -alh ~/vitaFlow/TEDLiumTestDataset/raw_data/train/sph/AaronHuey_2010X.sph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_sph_dir = test_sph_file = os.path.expanduser(\"~\") + \"/vitaFlow/TEDLiumTestDataset/raw_data/train/sph/\"\n",
    "test_sph_file = os.path.expanduser(\"~\") + \"/vitaFlow/TEDLiumTestDataset/raw_data/train/sph/AaronHuey_2010X.sph\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the wav from binary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(test_sph_file, mode=\"rb\") as file:\n",
    "        tmp = io.BytesIO(file.read())\n",
    "        print(tmp)\n",
    "        data, samplerate = sf.read(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samplerate, data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.waveplot(data, sr=samplerate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the Spectrum "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = librosa.stft(data)\n",
    "Xdb = librosa.amplitude_to_db(abs(X))\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.specshow(Xdb, sr=samplerate, x_axis='time', y_axis='hz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing Audio\n",
    "Using [IPython.display.Audio](https://ipython.org/ipython-doc/2/api/generated/IPython.lib.display.html#IPython.lib.display.Audio), you can play an audio file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ipd.Audio(data, rate=samplerate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Preprocessing with Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.16.58.105:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[4]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>shabda</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fdf07fa9470>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder. \\\n",
    "            master(\"local[4]\"). \\\n",
    "            appName(\"shabda\").getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wav_files_n_data = sc.binaryFiles(train_sph_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# files_bin_data = wav_files_n_data.map(lambda xy : xy).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_clips(file_path, data, num_clips=128, duration=20, output_dir=\"/tmp/\"):\n",
    "    file_path = file_path.replace(\"file:\", \"\")\n",
    "    tmp = io.BytesIO(data)\n",
    "    wav_data, sampling_rate = sf.read(tmp)\n",
    "    \n",
    "    speaker = file_path.split(\"/\")[-1].split(\".\")[0]\n",
    "    speaker_dir = os.path.join(output_dir, speaker)\n",
    "    if not os.path.exists(speaker_dir):\n",
    "        os.makedirs(speaker_dir)\n",
    "\n",
    "    y, _ = librosa.load(file_path, sr=sampling_rate)\n",
    "    end_time = librosa.get_duration(y=y, sr=sampling_rate)\n",
    "    for j in range(num_clips):\n",
    "        wav_file = os.path.join(speaker_dir, str(j)) + \".wav\"\n",
    "        k = int(np.random.randint(0, end_time, size=1))\n",
    "        librosa.output.write_wav(wav_file,\n",
    "                                 y[k*sampling_rate : (k+duration)*sampling_rate],\n",
    "                                 sampling_rate)\n",
    "                    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# files_bin_data[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to_clips(files_bin_data[0][0], files_bin_data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wav_files_n_data.foreach(lambda xy : to_clips(file_path=xy[0], data=xy[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([(\"1\",\"2\"),(\"1\",\"3\"),(\"2\",\"4\"),(\"4\",\"5\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdd = rdd.zipWithIndex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdd.map(lambda tuples : tuples[0][0]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_1 = spark.createDataFrame([['a',1],['a', 2]], ['string_col', 'int_col'])\n",
    "df_2 = spark.createDataFrame([[2,'b'], [1, 'b']], ['int_col', 'string_col'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+\n",
      "|string_col|int_col|\n",
      "+----------+-------+\n",
      "|         a|      1|\n",
      "|         a|      2|\n",
      "+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "|int_col|string_col|\n",
      "+-------+----------+\n",
      "|      2|         b|\n",
      "|      1|         b|\n",
      "+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+\n",
      "|string_col|int_col|\n",
      "+----------+-------+\n",
      "|         a|      1|\n",
      "|         a|      2|\n",
      "|         2|      b|\n",
      "|         1|      b|\n",
      "+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_3 = df_1.union(df_2)\n",
    "df_3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+\n",
      "|string_col|int_col|\n",
      "+----------+-------+\n",
      "|         a|      1|\n",
      "|         a|      2|\n",
      "|         b|      2|\n",
      "|         b|      1|\n",
      "+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_3 = df_1.select(*df_1.columns).union(df_2.select(*df_1.columns))\n",
    "df_3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+\n",
      "|Group|Date|\n",
      "+-----+----+\n",
      "|    A|2000|\n",
      "|    A|2002|\n",
      "|    A|2007|\n",
      "|    B|1999|\n",
      "|    B|2015|\n",
      "+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_1 = spark.createDataFrame([['A',2000],['A',2002], ['A',2007], ['B',1999], ['B',2015]], ['Group', 'Date'])\n",
    "df_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.window import *\n",
    "from pyspark.sql.functions import row_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+------+\n",
      "|Group|Date|rownum|\n",
      "+-----+----+------+\n",
      "|    B|2015|     1|\n",
      "|    B|1999|     2|\n",
      "|    A|2007|     1|\n",
      "|    A|2002|     2|\n",
      "|    A|2000|     3|\n",
      "+-----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_final = df_1.withColumn(\"rownum\", row_number().over(Window.partitionBy(\"Group\").orderBy(desc(\"Date\"))))\n",
    "df_final.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+\n",
      "|Group|Date|\n",
      "+-----+----+\n",
      "|    B|2015|\n",
      "|    A|2007|\n",
      "+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_final = df_1.withColumn(\"rownum\", row_number().over(Window.partitionBy(\"Group\").orderBy(desc(\"Date\")))).filter(\"rownum ==1\").drop(\"rownum\")\n",
    "df_final.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
